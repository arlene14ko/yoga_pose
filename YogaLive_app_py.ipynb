{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YogaLive - app.py",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDq_SvoM2rh",
        "outputId": "916fc133-ad02-42ef-acfa-494fab4eee35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9pUruwo7di4",
        "outputId": "f932b4a5-9f53-4238-a327-bc53ec2c649d"
      },
      "source": [
        "!pip install flask-ngrok mediapipe"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Collecting mediapipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/a9/423f5c7ac68ba94821656af72151887c7a22f7ef66ff6ec5edd8c577dbda/mediapipe-0.8.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1MB)\n",
            "\u001b[K     |████████████████████████████████| 36.1MB 78kB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (8.0.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (56.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.0)\n",
            "Installing collected packages: flask-ngrok, mediapipe\n",
            "Successfully installed flask-ngrok-0.0.25 mediapipe-0.8.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqpXi5We7nwB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "29e9060a-1f6b-4db1-9c14-701ad1317e91"
      },
      "source": [
        "# importing the necessary libraries\n",
        "from flask import (Flask,render_template,request,redirect,send_from_directory,Response)\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/YogaLive/templates', static_folder='/content/drive/MyDrive/YogaLive/static')\n",
        "run_with_ngrok(app)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "#model = pickle.load(open(\"yoga_poses_model.pkl\", \"rb\"))\n",
        "model = keras.models.load_model('/content/drive/MyDrive/YogaLive/final_model')\n",
        "\n",
        "@app.route(\"/\")\n",
        "@app.route(\"/home\")\n",
        "@app.route(\"/analyze\", methods=[\"GET\", \"POST\"])\n",
        "def analyze():\n",
        "    \"\"\"\n",
        "    Function that has both GET and POST method.\n",
        "    This is the function where it will ask the user input and \n",
        "    then analyze that input and return it back to the html file\n",
        "    \"\"\"\n",
        "    if request.method == \"GET\":\n",
        "        return render_template(\"analyze.html\")\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "\n",
        "        if \"file\" not in request.files:\n",
        "            return redirect(request.url)\n",
        "\n",
        "        file = request.files.get(\"file\")\n",
        "        print(f\"File Input: {file}\")\n",
        "\n",
        "        if file == \"\":\n",
        "            return redirect(request.url)\n",
        "\n",
        "        elif file:\n",
        "            print(\"Elif Uploaded Video file\")\n",
        "            print(file)\n",
        "            pass\n",
        "\n",
        "        else:\n",
        "            return render_template(\"analyze.html\")\n",
        "\n",
        "\n",
        "@app.route(\"/favicon.ico\")\n",
        "def favicon():\n",
        "    return send_from_directory(\n",
        "        os.path.join(app.root_path, \"static\"),\n",
        "        \"favicon.ico\",\n",
        "        mimetype=\"image/vnd.microsoft.icon\",\n",
        "    )\n",
        "\n",
        "\n",
        "@app.route(\"/live_feed\")\n",
        "def index():\n",
        "    \"\"\"\n",
        "    Video streaming home page.\n",
        "    \"\"\"\n",
        "    return render_template(\"live_feed.html\")\n",
        "\n",
        "\n",
        "\n",
        "def angles(a, b, c):\n",
        "    a = np.array(a)  # First\n",
        "    b = np.array(b)  # Mid\n",
        "    c = np.array(c)  # End\n",
        "\n",
        "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(\n",
        "        a[1] - b[1], a[0] - b[0]\n",
        "    )\n",
        "    angle = np.abs(radians * 180.0 / np.pi)\n",
        "\n",
        "    if angle > 180.0:\n",
        "        angle = 360 - angle\n",
        "\n",
        "    return angle\n",
        "\n",
        "\n",
        "def gen():\n",
        "    \"\"\"\n",
        "    Video streaming generator function.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    pose_counts = {\n",
        "        \"downward_facing_dog\": 0,\n",
        "        \"happy_baby_pose\": 0,\n",
        "        \"low_lunge\": 0,\n",
        "        \"half_split_pose\": 0,\n",
        "        \"child_pose\": 0,\n",
        "        \"cobra_pose\": 0,\n",
        "        \"cow_pose\": 0,\n",
        "        \"cat_pose\": 0,\n",
        "        \"high_plank\": 0,\n",
        "        \"easy_pose\": 0,\n",
        "        \"upward_facing_dog\": 0,\n",
        "        \"standing_forward_bend\": 0,\n",
        "    }\n",
        "    poses = {\n",
        "        \"downward_facing_dog\": 0,\n",
        "        \"happy_baby_pose\": 0,\n",
        "        \"low_lunge\": 0,\n",
        "        \"half_split_pose\": 0,\n",
        "        \"child_pose\": 0,\n",
        "        \"cobra_pose\": 0,\n",
        "        \"cow_pose\": 0,\n",
        "        \"cat_pose\": 0,\n",
        "        \"high_plank\": 0,\n",
        "        \"easy_pose\": 0,\n",
        "        \"upward_facing_dog\": 0,\n",
        "        \"standing_forward_bend\": 0,\n",
        "        \"low\": 0,\n",
        "    }\n",
        "\n",
        "    cap = cv2.VideoCapture(\"/content/drive/MyDrive/YogaLive/dataset/test1.mp4\")\n",
        "    \n",
        "    \n",
        "    with mp_pose.Pose(\n",
        "        min_detection_confidence=0.75, min_tracking_confidence=0.75\n",
        "    ) as pose:\n",
        "        while cap.isOpened():\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame = cap.read()\n",
        "            if ret == True:\n",
        "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                image.flags.writeable = False\n",
        "\n",
        "                \n",
        "                # Get landmarks from mediapipe pose\n",
        "                results = pose.process(image)\n",
        "                \n",
        "\n",
        "                # Recolor back to BGR\n",
        "                image.flags.writeable = True\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "            \n",
        "\n",
        "                try:\n",
        "\n",
        "                    # Get landmarks per joints\n",
        "                    landmarks = results.pose_landmarks.landmark\n",
        "                          # print(len(landmarks))\n",
        "\n",
        "                    left_shoulder = [\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,\n",
        "                    ]\n",
        "                    left_hip = [\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_HIP].y,\n",
        "                    ]\n",
        "                    left_knee = [\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y,\n",
        "                    ]\n",
        "                    left_elbow = [\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y,\n",
        "                    ]\n",
        "\n",
        "                    right_shoulder = [\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y,\n",
        "                    ]\n",
        "                    right_hip = [\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y,\n",
        "                    ]\n",
        "                    right_knee = [\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y,\n",
        "                    ]\n",
        "                    right_elbow = [\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x,\n",
        "                        landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y,\n",
        "                    ]\n",
        "\n",
        "                    # Model predict\n",
        "\n",
        "                    im_pil = Image.fromarray(image)\n",
        "\n",
        "                    # resize the array (image) then PIL image\n",
        "                    img = im_pil.resize((224, 224))\n",
        "                    img_data = np.expand_dims(img, axis=0)\n",
        "                    img_data = preprocess_input(img_data)\n",
        "\n",
        "                    preds = model.predict(img_data)\n",
        "                    model_class = np.argmax(preds, axis=1)[0]\n",
        "                    #print(model_class)\n",
        "                    #pose_count = {}  \n",
        "        \n",
        "                    if model_class == 0:\n",
        "                        pose_class = \"Adho Mukha Svanasana - Downward-Facing Dog\"\n",
        "                        poses[\"downward_facing_dog\"] += 1\n",
        "                        left_angle = round(\n",
        "                            angles(left_shoulder, left_hip, left_knee), 2\n",
        "                        )\n",
        "                        right_angle = round(\n",
        "                            angles(right_shoulder, right_hip, right_knee), 2\n",
        "                        )\n",
        "                        print(\n",
        "                            f\"Pose: {pose_class}, Left Angle: {left_angle}, Right Angle: {right_angle}\"\n",
        "                        )\n",
        "                        if (\n",
        "                            poses[\"downward_facing_dog\"] == 10\n",
        "                            and left_angle > 45\n",
        "                            and left_angle < 90\n",
        "                            and right_angle > 45\n",
        "                            and right_angle < 90\n",
        "                        ):\n",
        "                            class_pose = \"Downward-Facing Dog\"\n",
        "                            pose_counts[\"downward_facing_dog\"] += 1\n",
        "                            poses[\"downward_facing_dog\"] = 0\n",
        "                        elif poses[\"downward_facing_dog\"] == 10:\n",
        "                            class_pose = \"Downward-Facing Dog\"\n",
        "                            pose_counts[\"downward_facing_dog\"] += 1\n",
        "                            poses[\"downward_facing_dog\"] = 0\n",
        "\n",
        "                    elif model_class == 1:\n",
        "                        pose_class = \"Ananda Balasana - Happy Baby's Pose\"\n",
        "                        poses[\"happy_baby_pose\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"happy_baby_pose\"] == 10:\n",
        "                            class_pose = \"Ananda Balasana - Happy Baby's Pose\"\n",
        "                            pose_counts[\"happy_baby_pose\"] += 1\n",
        "                            poses[\"happy_baby_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 2:\n",
        "                        pose_class = \"Anjaneyasana - Low Lunge\"\n",
        "                        poses[\"low\"] += 1\n",
        "                        poses[\"low_lunge\"] += 1\n",
        "                        left_angle = round(angles(left_knee, left_hip, right_knee), 2)\n",
        "                        right_angle = round(angles(right_knee, right_hip, left_knee), 2)\n",
        "                        print(\n",
        "                            f\"Pose: {pose_class}, Left Angle: {left_angle}, Right Angle: {right_angle}\"\n",
        "                        )\n",
        "                        if poses[\"low_lunge\"] == 10:\n",
        "                            if left_angle > 100 or right_angle > 100:\n",
        "                                class_pose = \"Low Lunge\"\n",
        "                                pose_counts[\"low_lunge\"] += 1\n",
        "                                poses[\"low_lunge\"] = 0\n",
        "                        else:\n",
        "                            if left_angle > 100 and right_angle > 100:\n",
        "                                class_pose = \"Low Lunge\"\n",
        "                                poses[\"low\"] = 0\n",
        "\n",
        "                    elif model_class == 3:\n",
        "                        pose_class = \"Ardha Hanumanasana- Half Splits Pose\"\n",
        "                        poses[\"half_split_pose\"] += 1\n",
        "                        left_angle = round(\n",
        "                            angles(left_shoulder, left_hip, left_knee), 2\n",
        "                        )\n",
        "                        right_angle = round(\n",
        "                            angles(right_shoulder, right_hip, right_knee), 2\n",
        "                        )\n",
        "                        print(\n",
        "                            f\"Pose: {pose_class}, Left Angle: {left_angle}, Right Angle: {right_angle}\"\n",
        "                        )\n",
        "                        if (\n",
        "                            poses[\"half_split_pose\"] == 10\n",
        "                            and left_angle > 25\n",
        "                            and left_angle < 60\n",
        "                            and right_angle > 25\n",
        "                            and right_angle < 60\n",
        "                        ):\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Half Splits Pose\"\n",
        "                            pose_counts[\"half_split_pose\"] += 1\n",
        "                            poses[\"half_split_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 4:\n",
        "                        pose_class == \"Balasana - Child's Pose\"\n",
        "                        poses[\"child_pose\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"child_pose\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Child's Pose\"\n",
        "                            pose_counts[\"child_pose\"] += 1\n",
        "                            poses[\"child_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 5:\n",
        "                        pose_class = \"Bhujangasana - Cobra Pose\"\n",
        "                        poses[\"cobra_pose\"] += 1\n",
        "                        left_angle = round(\n",
        "                            angles(left_shoulder, left_hip, left_knee), 2\n",
        "                        )\n",
        "                        right_angle = round(\n",
        "                            angles(right_shoulder, right_hip, right_knee), 2\n",
        "                        )\n",
        "                        print(\n",
        "                            f\"Pose: {pose_class}, Left Angle: {left_angle}, Right Angle: {right_angle}\"\n",
        "                        )\n",
        "                        if (\n",
        "                            poses[\"cobra_pose\"] == 10\n",
        "                            and left_angle > 90\n",
        "                            and left_angle < 180\n",
        "                            and right_angle > 90\n",
        "                            and right_angle < 180\n",
        "                        ):\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Cobra Pose\"\n",
        "                            pose_counts[\"cobra_pose\"] += 1\n",
        "                            poses[\"cobra_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 6:\n",
        "                        pose_class = \"Bitilasana - Cow Pose\"\n",
        "                        poses[\"cow_pose\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"cow_pose\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Cow Pose\"\n",
        "                            pose_counts[\"cow_pose\"] += 1\n",
        "                            poses[\"cow_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 7:\n",
        "                        pose_class = \"Marjariasana - Cat Pose\"\n",
        "                        poses[\"cat_pose\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"cat_pose\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Cat Pose\"\n",
        "                            pose_counts[\"cat_pose\"] += 1\n",
        "                            poses[\"cat_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 8:\n",
        "                        pose_class = \"Phalakasana - High Plank\"\n",
        "                        poses[\"high_plank\"] += 1\n",
        "                        left_angle = round(\n",
        "                            angles(left_elbow, left_shoulder, left_knee), 2\n",
        "                        )\n",
        "                        right_angle = round(\n",
        "                            angles(right_elbow, right_shoulder, right_knee), 2\n",
        "                        )\n",
        "                        print(\n",
        "                            f\"Pose: {pose_class}, Left Angle: {left_angle}, Right Angle: {right_angle}\"\n",
        "                        )\n",
        "                        if (\n",
        "                            poses[\"high_plank\"] == 10\n",
        "                            and left_angle > 45\n",
        "                            and left_angle < 170\n",
        "                            and right_angle > 45\n",
        "                            and right_angle < 170\n",
        "                        ):\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"High Plank\"\n",
        "                            pose_counts[\"high_plank\"] += 1\n",
        "                            poses[\"high_plank\"] = 0\n",
        "\n",
        "                    elif model_class == 9:\n",
        "                        pose_class == \"Sukhasana - Easy Pose\"\n",
        "                        poses[\"easy_pose\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"easy_pose\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Easy Pose\"\n",
        "                            pose_counts[\"easy_pose\"] += 1\n",
        "                            poses[\"easy_pose\"] = 0\n",
        "\n",
        "                    elif model_class == 10:\n",
        "                        pose_class = \"Urdhva Mukha Svanasana - Upward-Facing Dog\"\n",
        "                        poses[\"upward_facing_dog\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"upward_facing_dog\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Upward-Facing Dog\"\n",
        "                            pose_counts[\"upward_facing_dog\"] += 1\n",
        "                            poses[\"upward_facing_dog\"] = 0\n",
        "\n",
        "                    elif model_class == 11:\n",
        "                        pose_class = \"Uttanasana - Standing Forward Bend\"\n",
        "                        poses[\"standing_forward_bend\"] += 1\n",
        "                        print(f\"Pose: {pose_class}, Left Angle: , Right Angle: \")\n",
        "                        if poses[\"standing_forward_bend\"] == 10:\n",
        "                            print(pose_class)\n",
        "                            class_pose = \"Standing Forward Bend\"\n",
        "                            pose_counts[\"standing_forward_bend\"] += 1\n",
        "                            poses[\"standing_forward_bend\"] = 0\n",
        "\n",
        "                    print(f\"Class Pose: {class_pose}\")\n",
        "                    # Setup status box\n",
        "                    cv2.rectangle(image, (0, 0), (800, 45), (245, 117, 230), -1)\n",
        "\n",
        "                    # Rep data\n",
        "                    cv2.putText(\n",
        "                        image,\n",
        "                        \"POSE: \",\n",
        "                        (15, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5,\n",
        "                        (0, 100, 0),\n",
        "                        1,\n",
        "                        cv2.LINE_AA,\n",
        "                    )\n",
        "\n",
        "                    cv2.putText(\n",
        "                        image,\n",
        "                        class_pose,\n",
        "                        (70, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        1,\n",
        "                        (255, 255, 255),\n",
        "                        2,\n",
        "                        cv2.LINE_AA,\n",
        "                    )\n",
        "\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                # cv2.imshow('Mediapipe Feed', image)\n",
        "                frame = cv2.imencode(\".jpg\", image)[1].tobytes()\n",
        "                yield (\n",
        "                    b\"--frame\\r\\n\" b\"Content-Type: image/jpeg\\r\\n\\r\\n\" + frame + b\"\\r\\n\"\n",
        "                )\n",
        "                # time.sleep(0.1)\n",
        "\n",
        "                if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
        "                    cap.release()\n",
        "                    cv2.destroyAllWindows()\n",
        "                    break\n",
        "\n",
        "            else:\n",
        "                print(pose_counts)\n",
        "                break\n",
        "\n",
        "@app.route(\"/video_feed\")\n",
        "def video_feed():\n",
        "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
        "    return Response(gen(), mimetype=\"multipart/x-mixed-replace; boundary=frame\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3df96c7718f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmp_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#model = pickle.load(open(\"yoga_poses_model.pkl\", \"rb\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/YogaLive/final_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m   \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;31m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   \"\"\"\n\u001b[0;32m--> 765\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m--> 890\u001b[0;31m                             ckpt_options, filters)\n\u001b[0m\u001b[1;32m    891\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                   self._checkpoint_options).expect_partial()\n\u001b[1;32m    486\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[1;32m   1336\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1337\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    965\u001b[0m           ._single_restoration_from_checkpoint_position(\n\u001b[1;32m    966\u001b[0m               \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m               visit_queue=visit_queue))\n\u001b[0m\u001b[1;32m    968\u001b[0m       \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       \u001b[0mtensor_saveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensor_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_single_restoration_from_checkpoint_position\u001b[0;34m(self, checkpoint_position, visit_queue)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                                []).append(child_position)\n\u001b[1;32m   1001\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mchild_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m           \u001b[0;31m# This object's correspondence is new, so dependencies need to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m           \u001b[0;31m# visited. Delay doing it so that we get a breadth-first dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mbind_object\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    305\u001b[0m                   proto_id=slot_restoration.slot_variable_id),\n\u001b[1;32m    306\u001b[0m               \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m               slot_name=slot_restoration.slot_name)\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# New assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_or_restore_slot_variable\u001b[0;34m(self, slot_variable_position, slot_name, variable)\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;31m# If we've either made this slot variable, or if we've pulled out an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       \u001b[0;31m# existing slot variable, we should restore it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m       \u001b[0mslot_variable_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;31m# We didn't make the slot variable. Defer restoring until it gets created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    971\u001b[0m     restore_ops.extend(\n\u001b[1;32m    972\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 973\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    974\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    306\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m    307\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0;32m--> 308\u001b[0;31m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       restored_tensors = io_ops.restore_v2(\n\u001b[0;32m--> 109\u001b[0;31m           file_prefix, tensor_names, tensor_slices, tensor_dtypes)\n\u001b[0m\u001b[1;32m    110\u001b[0m     structured_restored_tensors = nest.pack_sequence_as(\n\u001b[1;32m    111\u001b[0m         tensor_structure, restored_tensors)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m   1497\u001b[0m       return restore_v2_eager_fallback(\n\u001b[1;32m   1498\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1500\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0;32m-> 1537\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1538\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_HDKONL1iKN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}